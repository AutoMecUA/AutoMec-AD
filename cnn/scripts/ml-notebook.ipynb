{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e834d221",
   "metadata": {},
   "source": [
    "# AutoMecAD: ML Prototyping and Testing\n",
    "\n",
    "This notebook is used for the prototyping and evaluation of different ML models to be used for autonomous driving. </br>\n",
    "</br>\n",
    "<b> Attention: </b> You will <b> need </b> the Jupyter Notebook installed in order to run this notebook. We also recomend to install the conda enviroment with python 3.8 (Anaconda or miniconda) for an easier dependency management (install AutoMec-AD/requirements.txt + plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eef99c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization tools\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import plotly.express as px\n",
    "\n",
    "# Data manipulation\n",
    "from imgaug import augmenters as iaa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# ML Libraries\n",
    "from tensorflow.keras.layers import Convolution2D, Flatten, Dense, Dropout,  \\\n",
    "TimeDistributed, ConvLSTM2D, Input, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.python.keras.engine.sequential import relax_input_shape\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Other\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import pprint\n",
    "import random\n",
    "import shutil \n",
    "import yaml\n",
    "import os\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078ea6c",
   "metadata": {},
   "source": [
    "### Saving the original dataset\n",
    "If you want to store the augmented images in your disk, or join multiple datasets, you should clone the IMGs and logs to a new dataset and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "845cd3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:pwd:1: too many arguments\r\n"
     ]
    }
   ],
   "source": [
    "# path to the folder, or to the new folder to be created \n",
    "!pwd \n",
    "PATH = \"../data/setXteste12/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065192b3",
   "metadata": {},
   "source": [
    "Uncomment if you want to create a new folder for a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0eb88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # directory used to retrive images, steering angles and save new augmented images\n",
    "# try:\n",
    "#     shutil.rmtree(PATH)\n",
    "# except:\n",
    "#     print(\"tree not found\")\n",
    "#\n",
    "# os.mkdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73750253",
   "metadata": {},
   "source": [
    "Uncomment the code below if you want to create the new 'driving_log.csv' <br>\n",
    "Change the variable <code> PATHS </code> to choose the datasets that you want to join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc0fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = \"\"\n",
    "\n",
    "# # CHOOSE YOUR SETS, INSERT THE CORRESPONDED PATHS TO THOSE SETS\n",
    "# PATHS = [\"setX40/\", \"setX42/\"]\n",
    "\n",
    "# for i, path_log in enumerate(PATHS):\n",
    "#     file_data = ''\n",
    "#     with open(os.path.join(path_log, 'driving_log.csv')) as fp:\n",
    "#         file_data = fp.read()\n",
    "#     file_data = file_data + '\\n' if i < len(path_log)-1 else file_data # the last file read doesnt need the line break\n",
    "#     data = data + file_data\n",
    "\n",
    "# with open(PATH + 'driving_log.csv', 'w') as fp:\n",
    "#     fp.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a9b1e",
   "metadata": {},
   "source": [
    "Using your file manager to copy all the images and paste in the new dataset is faster. </br>\n",
    "Use only this piece of code if you don't want to manually paste them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8be18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DEMORA MUITO TEMPO\n",
    "\n",
    "# os.mkdir(os.path.join(PATH, 'IMG/'))\n",
    "\n",
    "# for path_img in PATHS:\n",
    "#     dir_ = os.listdir(os.path.join(path_img, 'IMG/'))\n",
    "#     for file in dir_:\n",
    "#         print(dir_)\n",
    "#         shutil.copy(os.path.join(path_img + 'IMG/', file), PATH + 'IMG/')\n",
    "\n",
    "# dir_ = os.listdir(PATH + 'IMG/')\n",
    "# print(len(dir_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00780539",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94f3f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20 \n",
    "steps_per_epoch = 100 \n",
    "batch_size_train = 20\n",
    "training_flag = 1\n",
    "batch_size_val = 25\n",
    "validation_flag = 0\n",
    "validation_steps = 50   \n",
    "\n",
    "image_width = 320\n",
    "image_height = 160"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ac1bb",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2472a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = ['img_name','steering', 'velocity'] \n",
    "df = pd.read_csv(os.path.join(PATH, 'driving_log.csv'), names = columns)\n",
    "\n",
    "del df[\"velocity\"] # not in use, currently\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860939b",
   "metadata": {},
   "source": [
    "# Image Data  Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b56456",
   "metadata": {},
   "source": [
    "In case you want to visualize the camera images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057ea69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgv_path = os.path.join(PATH, \"IMG/\")\n",
    "imgsv = os.listdir(imgv_path)\n",
    "rand_integer = random.randint(0, len(imgsv))\n",
    "imgv = cv2.imread(imgv_path + imgsv[rand_integer], cv2.IMREAD_COLOR)\n",
    "imgv_cropped = imgv[40:, :]\n",
    "plt.imshow(imgv_cropped)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfe4d3",
   "metadata": {},
   "source": [
    "## Data Annotation\n",
    "\n",
    "Annote Images with the Steering values (also known as labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e16452",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = [os.path.join(PATH, \"IMG\", df.iloc[i].img_name) for i in range(df.shape[0])]\n",
    "data  = np.column_stack((img_names, df.steering)) \n",
    "\n",
    "img_paths = data[:, 0] \n",
    "steerings = data[:, 1].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81718320",
   "metadata": {},
   "source": [
    "## 3-way Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3190b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(img_paths, steerings, test_size=0.11, random_state=5)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.11, random_state=5)\n",
    "\n",
    "print('Total Training Images: ', len(x_train))\n",
    "print('Total Validation Images: ', len(x_val))\n",
    "print('Total Testing Images: ', len(x_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b96a59",
   "metadata": {},
   "source": [
    "### Histogram of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_test              = 31 # Has to be an odd number so we have zero at the center\n",
    "freq_test, bins_test    = np.histogram(y_test, bins=nbins_test)\n",
    "\n",
    "\"\"\"\n",
    "Centered bins: \n",
    "    This creates a Bin with zero value for the center \n",
    "    (wich is what we expect from most of the driving input)\n",
    "\"\"\"\n",
    "cbins_test = (bins_test[:-1] + bins_test[1:])*0.5     \n",
    "\n",
    "fig = px.bar(x        = cbins_test, \n",
    "             y        = freq_test, \n",
    "             labels   = {'x' : 'Steering Angle', 'y' : 'Frequency  (Log Scale)'}, \n",
    "             title    = \"Steering Angle Distribuiton: TEST SET\",\n",
    "             template =\"plotly_dark\",\n",
    "             log_y    = False) #True\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced1a95",
   "metadata": {},
   "source": [
    "### Histogram of the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbedd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nbins_val              = 31        # Has to be an odd number so we have zero at the center\n",
    "freq_val, bins_val    = np.histogram(y_val, bins=nbins_val)\n",
    "\n",
    "\"\"\"\n",
    "Centered bins: \n",
    "    This creates a Bin with zero value for the center \n",
    "    (wich is what we expect from most of the driving input)\n",
    "\"\"\"\n",
    "cbins_val = (bins_val[:-1] + bins_val[1:])*0.5     \n",
    "\n",
    "fig = px.bar(x        = cbins_val, \n",
    "             y        = freq_val, \n",
    "             labels   = {'x' : 'Steering Angle', 'y' : 'Frequency  (Log Scale)'}, \n",
    "             title    = \"Steering Angle Distribuiton: VALIDATION SET\",\n",
    "             template =\"plotly_dark\",\n",
    "             log_y    = False) #True\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87ff3a",
   "metadata": {},
   "source": [
    "### Balance Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234aa71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_nsamples_val = 500\n",
    "\n",
    "for i in range(nbins_val): \n",
    "    \n",
    "    idx_rm = shuffle([ idx for idx, steering_value in enumerate(y_val)\n",
    "                               if steering_value >= bins_val[i] and steering_value <= bins_val[i+1] ])\n",
    "    \n",
    "    y_val = np.delete(y_val, idx_rm[keep_nsamples_val:]) \n",
    "    x_val = np.delete(x_val, idx_rm[keep_nsamples_val:]) \n",
    "\n",
    "print('Total val Images: ', len(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04621a91",
   "metadata": {},
   "source": [
    "### Balanced Histogram of the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_val, _ = np.histogram(y_val, nbins_val) # we already have our bins created...  steerings steerings\n",
    "\n",
    "fig = px.bar(x        = cbins_val, \n",
    "             y        = freq_val, \n",
    "             labels   = {'x' : 'Steering Angle', 'y' : 'Frequency'}, \n",
    "             title    = \"Steering Angle Distribuiton: VALIDATION SET (Trimmed)\",\n",
    "             template =\"plotly_dark\")\n",
    "\n",
    "fig.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf8f8b",
   "metadata": {},
   "source": [
    "## Balancing the Training Dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee60cd2e",
   "metadata": {},
   "source": [
    "###  Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0271e21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nbins         = 31        # Has to be an odd number so we have zero at the center\n",
    "freq, bins    = np.histogram(y_train, bins=nbins)\n",
    "\n",
    "\"\"\"\n",
    "Centered bins: \n",
    "    This creates a Bin with zero value for the center \n",
    "    (wich is what we expect from most of the driving input)\n",
    "\"\"\"\n",
    "cbins = (bins[:-1] + bins[1:])*0.5     \n",
    "\n",
    "fig = px.bar(x        = cbins, \n",
    "             y        = freq, \n",
    "             labels   = {'x' : 'Steering Angle', 'y' : 'Frequency '}, \n",
    "             title    = \"Steering Angle Distribuiton (in Log Scale)\",\n",
    "             template =\"plotly_dark\",\n",
    "             log_y    = False) #True\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae384e6",
   "metadata": {},
   "source": [
    "### Minority class OverSampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0d29e",
   "metadata": {},
   "source": [
    "The objective of this code was to oversampling the minority classes to be in equal frequency as the others... <br> Commented because it didn't gave much gain in performance to the CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08467639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Set threshold for the minority class\n",
    "# threshold_frequency = 100 # look the histogram to seek for the minority classes...\n",
    "\n",
    "# threshed_bins = np.array([[cb, f] for cb,f in zip(cbins, freq) if f < threshold_frequency])\n",
    "\n",
    "# mid_idx = int((len(threshed_bins)-1)/2)\n",
    "\n",
    "# far_pos_bin = threshed_bins[-1][0]\n",
    "# center_pos_bin = threshed_bins[mid_idx+1][0]\n",
    "# center_neg_bin = threshed_bins[mid_idx][0]\n",
    "# far_neg_bin = threshed_bins[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec8a78",
   "metadata": {},
   "source": [
    "Augmented Image pipeline for the minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a99bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AUGMENTED IMAGRE PIPELINE GENERATOR ,,,,\n",
    "# seq = iaa.Sequential([\n",
    "#     iaa.Sometimes(0.30, iaa.MotionBlur(k=15, angle=[-60, 60])), \n",
    "#     iaa.Sometimes(0.50, iaa.LinearContrast((0.5, 1.9))),\n",
    "#     iaa.Sometimes(0.20, iaa.Affine(shear=(-8, 8))),\n",
    "#     iaa.Sometimes(0.10, iaa.SaltAndPepper(0.05))\n",
    "# ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# for img_path, steer in zip(x_train, y_train): #img_paths steerings\n",
    "#     # if img is undersampled...\n",
    "#     if (steer <= center_neg_bin and steer >= far_neg_bin) or (steer >= center_pos_bin and steer <= far_pos_bin): \n",
    "        \n",
    "#         nimg = img_path.split(\".\")\n",
    "#         #create 8 augmented images  \n",
    "#         imgs = np.array( \n",
    "#             [ seq(images=[cv2.imread(img_path, cv2.IMREAD_COLOR)])[0] for i in range(3) ]  #530 8\n",
    "#         )\n",
    "#         for i,img in enumerate(imgs): \n",
    "#             # create a file name...\n",
    "#             name_file = nimg[0]+\"_{}.\".format(i)+nimg[1]\n",
    "#             # save new images... \n",
    "#             Image.fromarray(img).save(name_file)\n",
    "#             #update \n",
    "#             #new_row = np.array([name_file, steer])\n",
    "#             #data = np.vstack((data, new_row.reshape(-1, 2)))\n",
    "#             #img_paths = data[:, 0]\n",
    "#             #steerings = data[:, 1].astype(float)\n",
    "#             x_train = np.append(x_train, name_file)\n",
    "#             y_train = np.append(y_train, steer)\n",
    "#             #df.append(pd.DataFrame(new_row.reshape(1,-1), columns=list(df)), ignore_index=True) # dont work...\n",
    "#             print(counter)\n",
    "#             counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048621a",
   "metadata": {},
   "source": [
    "###  Undersampling\n",
    "</br>\n",
    "<!-- <font size=\"3\"> -->\n",
    "Iterates trough the bins... </br> </br>\n",
    "Checks if a given steering angle fits in the bin, which it means that is a part of a bin to crop</br> </br>\n",
    "Shuffles data fitted into a bin and keep only <code> keep_nsamples </code> \n",
    "<!-- </font> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd39b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keep_nsamples = 1900\n",
    "\n",
    "for i in range(nbins):   \n",
    "    \n",
    "    idx_rm = shuffle([ idx for idx, steering_value in enumerate(y_train)\n",
    "                               if steering_value >= bins[i] and steering_value <= bins[i+1] ]) # shuffle data\n",
    "    \n",
    "    x_train = np.delete(x_train, idx_rm[keep_nsamples:])\n",
    "    y_train = np.delete(y_train, idx_rm[keep_nsamples:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a34135a",
   "metadata": {},
   "source": [
    "### Histogram with data balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67062645",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "freq, _ = np.histogram(y_train, nbins) # we already have our bins created...\n",
    "\n",
    "fig = px.bar(x        = cbins, \n",
    "             y        = freq, \n",
    "             labels   = {'x' : 'Steering Angle', 'y' : 'Frequency'}, \n",
    "             title    = \"Steering Angle Distribuiton (Trimmed)\",\n",
    "             template =\"plotly_dark\",\n",
    "             log_y    = False)\n",
    "\n",
    "fig.show()  \n",
    "\n",
    "print(\"Total Training Images: \", len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a52bd5",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3455cb7",
   "metadata": {},
   "source": [
    "### Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a704b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(img, img_width=320, img_height=160, normalization=\"yes\"):\n",
    "    # Cropping Region of intrest, Ajust with Gazebo and use Andre Code in the Future\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2YUV) # For better jornalization \n",
    "    \n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0) \n",
    "    \n",
    "    img = cv2.resize(img, (img_width, img_height))  # NIVIDA uses 200x66\n",
    "\n",
    "    if normalization == \"yes\":\n",
    "        img = img/255\n",
    "\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c3510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentImage(imgPath, steering):\n",
    "    # Function: Add randomness to the data set by applying random \"filters\"\n",
    "\n",
    "    img = mpimg.imread(imgPath)\n",
    "\n",
    "    # Translation... PAN\n",
    "    if np.random.rand() < 0.30:\n",
    "        pan = iaa.Affine(translate_percent = {'x': (-0.1, 0.1) , 'y': (-0.1, 0.1)} )\n",
    "        img = pan.augment_image(img)  # Add a pan to img 5555 5   \n",
    "\n",
    "    # Zoom \n",
    "    if np.random.rand() < 0.30:\n",
    "        zoom = iaa.Affine(scale=(1, 1.2))\n",
    "        img = zoom.augment_image(img)\n",
    "\n",
    "    # Brightness\n",
    "    if np.random.rand() < 0.30:\n",
    "        brightness = iaa.Multiply((0.2, 1.2))\n",
    "        img = brightness.augment_image(img)\n",
    "    \n",
    "    #Motion Blur\n",
    "    if np.random.rand() < 0.30:\n",
    "        motion_blur = iaa.MotionBlur(k=15, angle=[-60, 60])\n",
    "        img = motion_blur.augment_image(img)\n",
    "        \n",
    "    #Contrast  \n",
    "    if np.random.rand() < 0.30:\n",
    "        lin_contrast = iaa.LinearContrast((0.5, 1.9))\n",
    "        img = lin_contrast.augment_image(img)\n",
    "    \n",
    "    # Shear Operation\n",
    "    if np.random.rand() < 0.30:\n",
    "        shear_img = iaa.Affine(shear=(-8, 8))\n",
    "        img = shear_img.augment_image(img)\n",
    "    \n",
    "    # Noise\n",
    "    if np.random.rand() < 0.30:\n",
    "        noise = iaa.SaltAndPepper(0.05)\n",
    "        img = noise.augment_image(img)\n",
    "    \n",
    "    # Random Ereasing / Occlusion\n",
    "    if np.random.rand() < 0.30:\n",
    "        occlusion = iaa.Cutout(nb_iterations=(1, 5), size=0.2, squared=False)\n",
    "        img = occlusion.augment_image(img)\n",
    "        \n",
    "    # Flip\n",
    "    if np.random.rand() < 0.30:\n",
    "        img = cv2.flip(img, 1)  \n",
    "        steering = - steering\n",
    "\n",
    "    return img, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab677ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchGen(imagesPath, steeringList, batchSize, trainFlag, imgwidth, imgheight):\n",
    "    # Creates a batch and applies augmentation\n",
    "    while True:\n",
    "        imgBatch = [] \n",
    "        steeringBatch = []   \n",
    "\n",
    "        for i in range(batchSize):\n",
    "            # Gets a random image and augments it\n",
    "            index = random.randint(0, len(imagesPath) - 1)\n",
    "            if trainFlag:\n",
    "                img, steering = augmentImage(imagesPath[index], steeringList[index])\n",
    "            else:\n",
    "                img = mpimg.imread(imagesPath[index])\n",
    "                steering = steeringList[index]\n",
    "            img = pre_processing(img, imgwidth, imgheight)\n",
    "\n",
    "            imgBatch.append(img)\n",
    "            steeringBatch.append(steering)\n",
    "\n",
    "        yield (np.asarray(imgBatch), np.asarray(steeringBatch)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1310e",
   "metadata": {},
   "source": [
    "## CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_nvidia(imgwidth, imgheight, nchannels): \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(24, (5, 5), (2, 2), input_shape=(imgheight, imgwidth, nchannels), activation='relu'))\n",
    "    model.add(Convolution2D(36, (5, 5), (2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(48, (5, 5), (2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(100, activation='relu'))  \n",
    "    \n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    \n",
    "    model.add(Dense(10, activation='elu'))\n",
    "   \n",
    "    model.add(Dense(1)) \n",
    "\n",
    "    model.compile(Adam(learning_rate=0.0001), loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps_per_epoch=32\n",
    "#epochs=25\n",
    "def cnn_rota(imgwidth, imgheight):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(8, (5, 5), (2, 2), input_shape=(imgheight, imgwidth, 3), activation='relu'))\n",
    "    model.add(Convolution2D(16, (5, 5), (2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(32, (5, 5), (2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(32, (5, 5), (1, 1), activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(375, activation='relu'))\n",
    "    #model.add(Dropout(rate=0.20)) #probability\n",
    "    model.add(Dense(125, activation='relu'))\n",
    "    #model.add(Dropout(rate=0.10)) #probability\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    \n",
    "    model.compile(Adam(learning_rate=0.0001), loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3beaa",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab06186",
   "metadata": {},
   "source": [
    "RNN model currently doesn't work, but it is interesting to see in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec74945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import toolz\n",
    "# from toolz.itertoolz import sliding_window\n",
    "\n",
    "# seq_len = 41\n",
    "\n",
    "# def create_sequences(size, data):\n",
    "#     sequence = list(sliding_window(size, data))\n",
    "#     sequence = np.array(sequence)\n",
    "#     return sequence\n",
    "\n",
    "# metax = create_sequences(seq_len, img_paths)\n",
    "# metay = create_sequences(seq_len, steerings)\n",
    "\n",
    "# x_train_lstm, x_test_lstm, y_train_lstm, y_test_lstm = train_test_split(metax, metay, test_size=0.10, random_state=5)\n",
    "# x_train_lstm, x_val_lstm, y_train_lstm, y_val_lstm = train_test_split(x_train_lstm, y_train_lstm, test_size=0.10, random_state=5)\n",
    "\n",
    "\n",
    "# print(x_train_lstm.shape)\n",
    "\n",
    "# def batchGen_lstm(imagesPath, steeringList, batchSize, trainFlag, imgwidth, imgheight):\n",
    "#     # Creates a batch and applies augmentation\n",
    "#     while True:\n",
    "#         imgBatch = [] \n",
    "#         steeringBatch = []   \n",
    "\n",
    "#         for i in range(batchSize):\n",
    "#             img_seqs = []\n",
    "#             steer_seqs = []\n",
    "#             for j in range(seq_len):\n",
    "#                 img = mpimg.imread(imagesPath[i][j])\n",
    "#                 steering = steeringList[i][j]\n",
    "#                 img = pre_processing(img, imgwidth, imgheight)\n",
    "#                 img_seqs.append( img)\n",
    "#                 steer_seqs.append( steering)\n",
    "                \n",
    "#             imgBatch.append(np.array(img_seqs))\n",
    "#             steeringBatch.append(np.array(steer_seqs))\n",
    "        \n",
    "#         imgBatch = shuffle(imgBatch)\n",
    "#         steeringBatch = shuffle(steeringBatch)\n",
    "        \n",
    "#         print(np.array(steeringBatch).shape)\n",
    "        \n",
    "#         yield (np.asarray(imgBatch), np.asarray(steeringBatch)) \n",
    "        \n",
    "\n",
    "# def cnn_lstm(imgwidth=320, imgheight=160):     \n",
    "#     model = Sequential()##########\n",
    "    \n",
    "#     model.add(ConvLSTM2D(filters = 24, \n",
    "#                          kernel_size = (5, 5), \n",
    "#                          strides=(2, 2),\n",
    "#                          activation = 'tanh',\n",
    "#                          data_format = \"channels_last\",\n",
    "#                          recurrent_dropout=0.2, \n",
    "#                          return_sequences=True, \n",
    "#                          input_shape = (seq_len, imgwidth, imgheight, 3))) \n",
    "#     model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "#     model.add(ConvLSTM2D(filters = 36, \n",
    "#                          kernel_size = (5, 5), \n",
    "#                          strides=(2, 2),\n",
    "#                          activation = 'tanh',\n",
    "#                          data_format = \"channels_last\",\n",
    "#                          recurrent_dropout=0.2, \n",
    "#                          return_sequences=True, \n",
    "#                          input_shape = (seq_len, imgwidth, imgheight, 3))) \n",
    "#     model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "#     model.add(ConvLSTM2D(filters = 48, \n",
    "#                          kernel_size = (5, 5), \n",
    "#                          strides=(2, 2),\n",
    "#                          activation = 'tanh',\n",
    "#                          data_format = \"channels_last\",\n",
    "#                          recurrent_dropout=0.2, \n",
    "#                          return_sequences=True, \n",
    "#                          input_shape = (seq_len, imgwidth, imgheight, 3))) \n",
    "#     model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "#     model.add(ConvLSTM2D(filters = 64, \n",
    "#                          kernel_size = (3, 3),\n",
    "#                          activation = 'tanh',\n",
    "#                          data_format = \"channels_last\",\n",
    "#                          recurrent_dropout=0.2, \n",
    "#                          return_sequences=True, \n",
    "#                          input_shape = (seq_len, imgwidth, imgheight, 3))) \n",
    "#     model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "#     model.add(ConvLSTM2D(filters = 64, \n",
    "#                          kernel_size = (3, 3),\n",
    "#                          activation = 'tanh',\n",
    "#                          data_format = \"channels_last\",\n",
    "#                          recurrent_dropout=0.2, \n",
    "#                          return_sequences=True, \n",
    "#                          input_shape = (seq_len, imgwidth, imgheight, 3))) \n",
    "#     model.add(TimeDistributed(Dropout(0.2)))\n",
    "    \n",
    "#     model.add(Flatten()) \n",
    "    \n",
    "#     #model.add(Dense(375, activation='relu'))\n",
    "#     #model.add(Dropout(rate=0.20)) #probability\n",
    "#     #model.summary()\n",
    "#     ##model.compile(Adam(learning_rate=np.exp(-5)), loss='mse')\n",
    "#     model.add(Dense(125, activation='relu'))\n",
    "#     model.add(Dense(25, activation='relu'))\n",
    "#     model.add(Dense(1, activation='tanh'))\n",
    "    \n",
    "#     model.compile(Adam(learning_rate=0.0001), loss='mse')\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196e4fe",
   "metadata": {},
   "source": [
    "## CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8cf1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = cnn_nvidia(imgwidth=320, imgheight=160, nchannels=3)\n",
    "#model = load_model('cnn_40_42_1200epochs_0015.h5') # you can also load a pre-trained model...\n",
    "model.summary()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af796b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cp_callback = ModelCheckpoint(filepath=\"callbacks/cp.ckpt\", save_weights_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    batchGen(x_train, y_train, batch_size_train, training_flag, image_width, image_height),\n",
    "    steps_per_epoch  = steps_per_epoch,\n",
    "    epochs           = epochs,\n",
    "    validation_data  = batchGen(x_val, y_val, batch_size_val, validation_flag, image_width, image_height),\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks        = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a390e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(history.history)\n",
    "\n",
    "\n",
    "fig = px.line(dataframe, \n",
    "              title    = 'Learning Curve', \n",
    "              labels   = {'x' : 'Epoch', 'y' : 'Loss Value '}, \n",
    "              template = \"plotly_dark\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb63f5b",
   "metadata": {},
   "source": [
    "## Model Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67d14d",
   "metadata": {},
   "source": [
    "### Compute Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209f3d29",
   "metadata": {},
   "source": [
    "Convert image paths to pre-processed opencv images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_images = np.asarray(\n",
    "    [ pre_processing(cv2.imread(img_file), image_width, image_height) for img_file in x_test]\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8f44d",
   "metadata": {},
   "source": [
    "Predict steering based on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fb3ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steering_predict = model.predict(x_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f711b1",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d640b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, steering_predict)\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "#count_positives = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63dfc4b",
   "metadata": {},
   "source": [
    "### Seeing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618041d",
   "metadata": {},
   "source": [
    "Uncomment if you want to see images with data augmentation techniques and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pre_process(img, img_width=320, img_height=160, normalization=\"yes\"):\n",
    "    \n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # For better jornalization\n",
    "    \n",
    "\n",
    "#     ret,img = cv2.threshold(img,190,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "#     img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, (10, 10))\n",
    "    \n",
    "#     img = cv2.GaussianBlur(img, (3, 3), 0)   \n",
    "    \n",
    "#     img = cv2.resize(img, (img_width, img_height))  # NIVIDA uses 200x66\n",
    "    \n",
    "#     if normalization == \"yes\":\n",
    "#         img = img/255\n",
    "\n",
    "#     return img \n",
    "\n",
    "# def augment_Image(imgPath):\n",
    "#     # Function: Add randomness to the data set by applying random \"filters\"\n",
    "    \n",
    "#     img = imgPath\n",
    "\n",
    "#     # Translation... PAN\n",
    "#     if np.random.rand() < 0.30:\n",
    "#         pan = iaa.Affine(translate_percent = {'x': (-0.1, 0.1) , 'y': (-0.1, 0.1)} )\n",
    "#         img = pan.augment_image(img)  # Add a pan to img 5555 5   \n",
    "\n",
    "#     # Zoom \n",
    "#     if np.random.rand() < 0.30:\n",
    "#         zoom = iaa.Affine(scale=(1, 1.2))\n",
    "#         img = zoom.augment_image(img)\n",
    "\n",
    "#     # Brightness\n",
    "#     if np.random.rand() < 0.30:\n",
    "#         brightness = iaa.Multiply((0.2, 1.2))\n",
    "#         img = brightness.augment_image(img)\n",
    "    \n",
    "#     #Motion Blur\n",
    "#     if np.random.rand() < 0.30:\n",
    "#         motion_blur = iaa.MotionBlur(k=15, angle=[-60, 60])\n",
    "#         img = motion_blur.augment_image(img)\n",
    "        \n",
    "#     #Contrast  \n",
    "#     if np.random.rand() < 0.30:\n",
    "#         lin_contrast = iaa.LinearContrast((0.5, 1.9))\n",
    "#         img = lin_contrast.augment_image(img)\n",
    "    \n",
    "#     # Shear Operation\n",
    "#     if np.random.rand() < 0.30:\n",
    "#         shear_img = iaa.Affine(shear=(-8, 8))\n",
    "#         img = shear_img.augment_image(img)\n",
    "    \n",
    "#     # Noise\n",
    "#     if np.random.rand() < 0.30:\n",
    "#         noise = iaa.SaltAndPepper(0.05)\n",
    "#         img = noise.augment_image(img)\n",
    "    \n",
    "#     # Random Ereasing / Occlusion\n",
    "#     if np.random.rand() < 0.30:\n",
    "#         occlusion = iaa.Cutout(nb_iterations=(1, 5), size=0.2, squared=False)\n",
    "#         img = occlusion.augment_image(img)\n",
    "        \n",
    "#     # Flip\n",
    "#     if np.random.rand() < 0.30:\n",
    "#         img = cv2.flip(img, 1)\n",
    "\n",
    "#     return img #, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0b8b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_image():\n",
    "    \n",
    "    rand_integer = random.randint(0, len(x_val))\n",
    "    \n",
    "    selectx = x_val[rand_integer]\n",
    "    #img = augment_Image(pre_process(mpimg.imread(selectx), img_width=320, img_height=160, normalization=\"no\"))\n",
    "    img = mpimg.imread(selectx)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    y_test_aux = y_val[rand_integer]\n",
    "    y_pred = steering_predict[rand_integer]\n",
    "    print(\"Predicted angle: \", round(y_pred[0], 5))\n",
    "    print(\"Real angle:      \", round(y_test_aux, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image()\n",
    "display_image()\n",
    "display_image()\n",
    "display_image()\n",
    "display_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f30c4",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86190cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m modelname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_40_42_1200epochs_0015.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(modelname)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "modelname = 'cnn_40_42_1200epochs_0015.h5'\n",
    "model.save(modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75085f5",
   "metadata": {},
   "source": [
    "### YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71fb4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read YAML file\n",
    "with open(PATH + \"info.yaml\", 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "data_loaded['dataset']['name'] = PATH.split('/')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39292c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_name = 'rota'\n",
    "val_loss = '0.01'\n",
    "test_loss = '0.02'\n",
    "model_evaluation = '5/10'\n",
    "ml_comments = 'correu mt bem... nao gostei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1369a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data = dict(\n",
    "    model = dict(\n",
    "        name = modelname,\n",
    "        developer = os.getenv('automec_developer'),\n",
    "        date = datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "        ml_arch = {\"name\":cnn_model_name, \"epochs\":epochs, \n",
    "                   \"batch_size_train\":batch_size_train, \n",
    "                   \"batch_size_val\":batch_size_val, \"training_flag\":training_flag,\n",
    "                   \"validation_flag\":validation_flag, \"validation_steps\":validation_steps,\n",
    "                   \"val_loss\":val_loss, \"tes_loss\":test_loss},\n",
    "        model_eval = model_evaluation,\n",
    "        comments = ml_comments\n",
    "    ),\n",
    "    dataset = data_loaded['dataset']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee6ed749",
   "metadata": {},
   "outputs": [],
   "source": [
    "yamlname = modelname.split(\".\")[0]\n",
    "with open('../models'+'/' + yamlname + '.yaml', 'w') as outfile: #info\n",
    "    yaml.dump(info_data, outfile, default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65965d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
